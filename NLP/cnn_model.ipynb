{"cells":[{"cell_type":"markdown","metadata":{"id":"JLw0fN90I6-M"},"source":["# **CNN Model**"]},{"cell_type":"markdown","metadata":{"id":"nG6Do5H57-UT"},"source":["# **Data Format:**\n","# **Columns: Text, Label**\n","## **Label: tuple of labels - Representing the multiclass classification**\n","\n","|  TEXT  |         LABEL        | \n","|--------|----------------------|\n","| TEXT_1 |  (LABEL_1, LABEL_3)  |\n","| TEXT_2 |  (LABEL_1)           |\n","| TEXT_3 |  (LABEL_2, LABEL_4)) |"]},{"cell_type":"markdown","metadata":{"id":"paTCnjiK8mwk"},"source":["# **GPU Configuration**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4216,"status":"ok","timestamp":1650460348608,"user":{"displayName":"Gabriel Medeiros","userId":"00840483478177331557"},"user_tz":180},"id":"5EISZQ74I6-Q","outputId":"29be286b-349d-4e7a-eba2-f8b84183e173"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","import os\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n","tf.config.list_physical_devices('GPU')\n","tf.test.is_built_with_cuda()"]},{"cell_type":"markdown","metadata":{"id":"rKQAQkbntUC0"},"source":["# **Load Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"faNQ21LE8rKf"},"outputs":[],"source":["from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCWvfrZVouzO"},"outputs":[],"source":["import pandas as pd\n","\n","csv_path = \"\"\n","data = pd.read_csv(csv_path)\n","data.head(5)"]},{"cell_type":"markdown","metadata":{"id":"UbSgR6oEI6-o"},"source":["# **Label Analysis**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJvl5BRt9ZLS"},"outputs":[],"source":["df = data.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKx-ULM6I6-q","tags":[]},"outputs":[],"source":["import plotly.express as px\n","df_test = df.label.apply(lambda x: str(x))\n","fig = px.histogram(df_test, x=\"label\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzxrnATZI6-s"},"outputs":[],"source":["import random\n","\n","def reduceData(df, n=10000000):\n","    dic = df.groupby(by=\"label\").groups\n","    selected_texts = []\n","    selected_labels = []\n","    selected_id = []\n","    for k in dic.keys():\n","        if (len(dic[k]) > n):\n","            dic[k] = random.sample(list(dic[k]), n)\n","        for i in dic[k]:\n","            selected_labels.append(k)\n","            selected_texts.append(df.text[i])\n","    return pd.DataFrame(data={\"text\": selected_texts, \"label\": selected_labels})\n","\n","df = reduceData(df, 500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rxYQz5bI6-u"},"outputs":[],"source":["df_test = df.label.apply(lambda x: str(x))\n","fig = px.histogram(df_test, x=\"label\")\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"_pN0qZRrI6-w"},"source":["# **Text Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXAvWLczI6-x"},"outputs":[],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","import string\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","\n","def removePunctuation(t):\n","    punc = string.punctuation\n","    for e in t:\n","        if e in punc:\n","            t = t.replace(e, \"\")\n","    return t\n","\n","def removeStopWordsStemmer(sentence, ps):\n","    sentence_tokens = word_tokenize(sentence)\n","    sentence_without_sw = [word for word in sentence_tokens if not word in stopwords.words()]\n","    sentence_without_sw = list(map(lambda s: ps.stem(s), sentence_without_sw))\n","    return \" \".join(sentence_without_sw)\n","\n","ps = PorterStemmer()\n","df.text = df.text.apply(lambda t: t.lower())\n","df.text = df.text.apply(lambda t: removePunctuation(t))\n","df.text = df.text.apply(lambda t: removeStopWordsStemmer(t, ps))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RN3NWWKcI6-0"},"outputs":[],"source":["import functools\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def textPreprocessing(texts):\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(texts)\n","    texts = tokenizer.texts_to_sequences(texts)\n","    vocab_size = len(tokenizer.word_index)\n","    max = len(functools.reduce(lambda a, b: a if len(a) > len(b) else b, texts))\n","    texts = pad_sequences(texts, maxlen = max, padding= \"pre\")\n","    return texts, vocab_size, max\n","\n","texts, vocab_size, max_ = textPreprocessing(list(df.text.values))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YljE13OjI6-1"},"outputs":[],"source":["df.text = list(texts)\n","df.head(5)"]},{"cell_type":"markdown","metadata":{"id":"FvZUfSwGI6-2"},"source":["# **Labels Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJ3BBfEd_urV"},"outputs":[],"source":["df.label = df.label.apply(lambda x: (x.split(\".\")[2],))\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltvMIzGEI6-3"},"outputs":[],"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","\n","def labelsPreprocessing(labels):\n","    mlb = MultiLabelBinarizer()\n","    labels = mlb.fit_transform(labels)\n","    return labels, mlb\n","\n","labels, encoder = labelsPreprocessing(list(df.label.values))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUWqaf3EI6-4"},"outputs":[],"source":["df.label = list(labels)\n","df.label = df.label.apply(lambda x: tuple(x))\n","df.head(5)"]},{"cell_type":"markdown","metadata":{"id":"giVa-aaoI6-5"},"source":["# **Treating Unbalanced Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQupOj7XI6-6"},"outputs":[],"source":["#from imblearn.under_sampling import NearMiss\n","#undersample = NearMiss(version=1, n_neighbors=1)\n","#texts_tr, labels_tr = undersample.fit_resample(texts, labels)\n","#len(texts_tr), len(labels_tr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrvSYnHsI6-7","tags":[]},"outputs":[],"source":["#from imblearn.under_sampling import TomekLinks\n","#tl = TomekLinks(sampling_strategy='majority')\n","#texts_tr, labels_tr = tl.fit_resample(texts, labels)\n","#len(texts_tr), len(labels_tr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DltsrXbHI6-8"},"outputs":[],"source":["#from imblearn.under_sampling import NeighbourhoodCleaningRule\n","#undersample = NeighbourhoodCleaningRule(n_neighbors=500, threshold_cleaning=0.5)\n","#texts_tr, labels_tr = undersample.fit_resample(texts, labels)\n","#len(texts_tr), len(labels_tr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrQgfw0SI6--","tags":[]},"outputs":[],"source":["#from imblearn.under_sampling import OneSidedSelection\n","#undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n","#texts_tr, labels_tr = undersample.fit_resample(texts, labels)\n","#len(texts_tr), len(labels_tr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PjUrgtGI6_A"},"outputs":[],"source":["#from imblearn.under_sampling import EditedNearestNeighbours\n","#undersample = EditedNearestNeighbours(n_neighbors=4)\n","#texts_tr, labels_tr = undersample.fit_resample(texts, labels)\n","#len(texts_tr), len(labels_tr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRrXrfNcI6_B"},"outputs":[],"source":["#from imblearn.under_sampling import CondensedNearestNeighbour\n","#undersample = CondensedNearestNeighbour(n_neighbors=1)\n","#texts_tr, labels_tr = undersample.fit_resample(texts, labels)\n","#len(texts_tr), len(labels_tr)"]},{"cell_type":"markdown","metadata":{"id":"mZuAtBcrI6_D","tags":[]},"source":["# **Training Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Flo_q8-QI6_D","tags":[]},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","from sklearn.metrics import classification_report\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import matthews_corrcoef\n","import numpy as np\n","from sklearn.metrics import multilabel_confusion_matrix\n","\n","def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=20):\n","\n","    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n","\n","    sn.set(font_scale=1.4)\n","\n","    try:\n","        heatmap = sn.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes, cmap='Blues')\n","    except ValueError:\n","        raise ValueError(\"Confusion matrix values must be integers.\")\n","        \n","    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n","    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n","    axes.set_ylabel('True label')\n","    axes.set_xlabel('Predicted label')\n","    axes.set_title(\"Confusion Matrix for the class - \" + class_label)\n","\n","def plotMultiLabelConfusionMatrices(cms, labels):\n","    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n","    for axes, conf_matrix, label in zip(ax.flatten(), cms, labels):\n","        print_confusion_matrix(conf_matrix, axes, label, [\"N\", \"Y\"])\n","\n","def generateModel(vocab_size, input_length, output_length):\n","    embedding_dim = 100\n","    model = Sequential()\n","    model.add(layers.Embedding(vocab_size + 1, embedding_dim, input_length=input_length))\n","    model.add(layers.Conv1D(128, 5, activation='relu'))\n","    model.add(layers.GlobalMaxPooling1D())\n","    model.add(layers.Dense(10, activation='relu'))\n","    model.add(layers.Dense(output_length, activation='sigmoid'))\n","    model.compile(optimizer='adam',\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    model.summary()\n","    return model\n","    \n","def defineLabel(prediction, threshold):\n","  r = []\n","  for p in prediction:\n","    r += [0] if p < threshold else [1]\n","  return tuple(r)\n","\n","def runModel(texts, labels, vocab_size, input_length, output_length, encoder, epochs, class_names):\n","    X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=3)\n","    X_train, X_test = np.array(X_train), np.array(X_test)\n","    y_train, y_test = np.array(y_train), np.array(y_test)\n","\n","    model = generateModel(vocab_size, input_length, output_length)\n","    model.fit(X_train, y_train, epochs=epochs, batch_size=10)\n","    \n","    y_pred = []\n","    for prediction in model.predict(X_test):\n","        prediction = list(prediction)\n","        pred_t = defineLabel(prediction, 0.5)\n","        y_pred.append(pred_t)\n","    \n","    print(classification_report(y_test, y_pred, target_names = class_names))\n","    \n","    cms = multilabel_confusion_matrix(y_test, y_pred)\n","    labels = class_names # Labels in alphabetic order\n","    plotMultiLabelConfusionMatrices(cms, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SB0_5UvaI6_G"},"outputs":[],"source":["output_size = len(labels[0])\n","class_names = ['a', 'b', 'c', 'd', 'e', 'f']\n","runModel(list(df.text.values), list(df.label.values), vocab_size, max_, output_size, encoder, 2, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRljYkyFEsJv"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"cnn_model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
